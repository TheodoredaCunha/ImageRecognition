{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelBuilder.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxzp1vZjbNXx"
      },
      "source": [
        "Loading Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a7JXTl8EQgC"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.datasets import fashion_mnist\r\n",
        "from keras.layers import Dense, Flatten, LSTM, Embedding, Dropout, Conv2D, MaxPooling2D"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fYbUcTYGTh3"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f6Qhn_MbRqe"
      },
      "source": [
        "Loading and Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyRXL2WKF5hY",
        "outputId": "7122f4f1-ee16-45a1-889d-84e206ecf6a6"
      },
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\r\n",
        "print(test_images.shape)\r\n",
        "\r\n",
        "train_labels = keras.utils.to_categorical(train_labels, 10)\r\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\r\n",
        "\r\n",
        "test_labels = keras.utils.to_categorical(test_labels, 10)\r\n",
        "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "(10000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZFIC8ksmve3"
      },
      "source": [
        "# Showing Dataset\r\n",
        "for i in range(100):\r\n",
        "  matplotlib_image = np.array(test_images[i]).reshape(1, 28, 28)\r\n",
        "  plt.imshow(matplotlib_image[0])\r\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD1AZQ-1K5J-"
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\r\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\r\n",
        "#class_names = [0, 1,2,3,4,5,6,7,8,9]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BZinTvkp2Q8u"
      },
      "source": [
        "#making the model\r\n",
        "moodel = Sequential()\r\n",
        "moodel.add(Conv2D(32, kernel_size = (3,3), activation = \"relu\", input_shape = (28, 28, 1)))\r\n",
        "moodel.add(Conv2D(64, (3, 3), activation='relu'))\r\n",
        "moodel.add(MaxPooling2D(pool_size = (2,2)))\r\n",
        "moodel.add(Dropout(0.25))\r\n",
        "moodel.add(Flatten())\r\n",
        "moodel.add(Dense(128, activation='relu'))\r\n",
        "moodel.add(Dropout(0.5))\r\n",
        "moodel.add(Dense(10, activation='softmax'))\r\n",
        "moodel.compile(loss = \"categorical_crossentropy\", optimizer = \"adadelta\", metrics = [\"accuracy\"])\r\n",
        "\r\n",
        "moodel.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64GS2Iss37fn"
      },
      "source": [
        "#Training the model\r\n",
        "print(train_images[0])\r\n",
        "print(train_labels[0])\r\n",
        "print(type(train_labels))\r\n",
        "good_enough = True\r\n",
        "while not good_enough:\r\n",
        "  moodel.fit(train_images, train_labels, epochs = 20, batch_size = 128, verbose = 1)\r\n",
        "  if moodel.evaluate(test_images, test_labels, verbose = 0)[1] > 0.90:\r\n",
        "    good_enough = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FcB364u1H6M8",
        "outputId": "e71af4ca-889f-4a68-b057-487e65ea4fb3"
      },
      "source": [
        "#Evaluate Model\r\n",
        "moodel.evaluate(test_images, test_labels, verbose = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3767894506454468, 0.8668000102043152]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUhKz0dbIoOM"
      },
      "source": [
        "#Get an examples data from dataset\r\n",
        "def get_example(test_index):\r\n",
        "  test = np.array([test_images[test_index]])\r\n",
        "  print(test.shape)\r\n",
        "  prediction = list(moodel.predict(test)[0])\r\n",
        "  answer = prediction.index(max(prediction))\r\n",
        "  res = class_names[answer]\r\n",
        "  print(res)\r\n",
        "  plt.figure()\r\n",
        "  show_image = test_images.reshape(10000, 28, 28)\r\n",
        "  plt.imshow(show_image[test_index])\r\n",
        "  plt.colorbar()\r\n",
        "  plt.grid(False)\r\n",
        "  plt.show()\r\n",
        "  return res\r\n",
        "\r\n",
        "counter = 0\r\n",
        "while get_example(counter) != \"Trouser\":\r\n",
        "  counter += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TY1AROubzKZ"
      },
      "source": [
        "Testing the camera feature:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3teqiHiaGbE"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "import matplotlib.image as mpimg\n",
        "import io\n",
        "import cv2\n",
        "#import imutils\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      console.log(video.width, video.height);\n",
        "      canvas.width = 550;\n",
        "      canvas.height = 450;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  binary = b64decode(data.split(',')[1])\n",
        "  image = io.BytesIO(binary)\n",
        "  i = mpimg.imread(image, format='JPG')\n",
        "  resized = cv2.resize(i, (28, 28))\n",
        "  #resized = imutils.resize(i, width =28)\n",
        "  gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
        "  plt.imshow(gray, interpolation='nearest')\n",
        "  plt.show()\n",
        "  gray = np.array(gray)\n",
        "  print(gray.shape)\n",
        "  fixed = []\n",
        "  for i in gray:\n",
        "    current = []\n",
        "    for j in i:\n",
        "      if j <= 15:\n",
        "        current.append([5])\n",
        "      else:\n",
        "        current.append([j])\n",
        "    fixed.append(current)\n",
        "  return fixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ez5tp8jd_rzI"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 351
        },
        "id": "WJeVHqQxa9c5",
        "outputId": "c7bfdc72-a67a-47c9-b8ce-eb36b03906f5"
      },
      "source": [
        "resized = take_photo()\r\n",
        "photo = []\r\n",
        "#resized = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\r\n",
        "#resized = resized[:, :, 0]\r\n",
        "photo.append(resized)\r\n",
        "photo = np.array(photo)\r\n",
        "photo.reshape(1, 28, 28, 1)\r\n",
        "print(photo.shape)\r\n",
        "p = moodel.predict(photo)\r\n",
        "print(p)\r\n",
        "results_index = list(p[0]).index(max(list(p[0])))\r\n",
        "class_names[results_index]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function takePhoto(quality) {\n",
              "      const div = document.createElement('div');\n",
              "      const capture = document.createElement('button');\n",
              "      capture.textContent = 'Capture';\n",
              "      div.appendChild(capture);\n",
              "\n",
              "      const video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
              "\n",
              "      document.body.appendChild(div);\n",
              "      div.appendChild(video);\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      // Resize the output to fit the video element.\n",
              "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
              "\n",
              "      // Wait for Capture to be clicked.\n",
              "      await new Promise((resolve) => capture.onclick = resolve);\n",
              "\n",
              "      const canvas = document.createElement('canvas');\n",
              "      console.log(video.width, video.height);\n",
              "      canvas.width = 550;\n",
              "      canvas.height = 450;\n",
              "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
              "      stream.getVideoTracks()[0].stop();\n",
              "      div.remove();\n",
              "      return canvas.toDataURL('image/jpeg', quality);\n",
              "    }\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(28, 28)\n",
            "(1, 28, 28, 1)\n",
            "[[2.7496559e-03 9.7217780e-01 4.6777682e-04 6.6032219e-03 6.8599416e-04\n",
            "  4.0511503e-03 1.0339219e-02 2.0392106e-03 3.3851288e-04 5.4745656e-04]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Trouser'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SElFVjrAb8Qe"
      },
      "source": [
        "Testing Model Saving and Loading:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYLsDwP2KmpZ",
        "outputId": "0e001cc3-88c2-40db-d67e-3a1e9a78c4ea"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4sowLIOzKwph",
        "outputId": "405568e9-7fd0-403b-cd73-071cb3858902"
      },
      "source": [
        "moodel.save(\"/content/gdrive/MyDrive/ImageRecognition/model/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/ImageRecognition/model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfqLlE0LLXNH"
      },
      "source": [
        "moodel.save(\"/content/gdrive/MyDrive/ImageRecognition/h5/my_model.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNmufZGRTJuI"
      },
      "source": [
        "from keras.models import load_model\r\n",
        "new_model = load_model(\"/content/gdrive/MyDrive/ImageRecognition/model/\")\r\n",
        "new_model.summary()\r\n",
        "eval = new_model.evaluate(test_images, test_labels, verbose = 1)\r\n",
        "print(\"The model has a loss of {} \\nThe model is {}% accurate\".format(eval[0], round(eval[1]*100)))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}